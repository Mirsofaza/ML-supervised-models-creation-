{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates how to implement Boosting/random forest and stacking for ensemble learning."
      ],
      "metadata": {
        "id": "JIM9w14C93Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part I: Manual implementation of Bagging"
      ],
      "metadata": {
        "id": "P1P71dzm-BdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b92YEI7oMcz1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create a synthetic, more complex dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "                           n_classes=3, flip_y=0.03, class_sep=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Parameters\n",
        "B = 100  # Number of bootstrap samples/models\n",
        "\n",
        "# Initialize lists to store predictions\n",
        "consensus_predictions = []\n",
        "probability_predictions = []\n",
        "\n",
        "# Bagging\n",
        "for b in range(B):\n",
        "    # Bootstrap sample by using scikit-learn library. This approach does not estimate out-of-bag samples but is concise\n",
        "    # It randomly selects samples from the original dataset with replacement, thus creating a new dataset\n",
        "    # that is the same size as the original but potentially with some data points repeated and others omitted.\n",
        "    X_train_b, y_train_b =\n",
        "\n",
        "    ''' Remember before we used the following masking method from numpy to do boostrapping to estimate Err^(.632+).\n",
        "        This is necessary if we want to know out-of-bag samples for analysis. It is more complex.\n",
        "        for _ in range(B): # Run B times\n",
        "            # Use the mask technique to select what are boostrap sets and what are out of bags\n",
        "            indices = np.arange(N)\n",
        "            bootstrap_indices = np.random.choice(indices, size=N, replace=True)\n",
        "            oob_mask = np.ones(N, dtype=bool)\n",
        "            oob_mask[bootstrap_indices] = 0\n",
        "            X_b, y_b = X[bootstrap_indices], y[bootstrap_indices]\n",
        "            X_oob, y_oob = X[oob_mask], y[oob_mask]\n",
        "    '''\n",
        "\n",
        "\n",
        "    # Train a model\n",
        "    model =  #Depth control or slip control can be necessary. Otherwise, weak learners can have overfit.\n",
        "    model.\n",
        "\n",
        "    # Consensus prediction (class prediction)\n",
        "    # X_test has 200 data\n",
        "    consensus_predictions. #(100,) A list of 100 arrays, each array include 200 elements for X_test\n",
        "\n",
        "    # Probability prediction based on the proportion of the training instances of each class in the leaf node\n",
        "    # In other words, it is the relative frequency of that class within the leaf node where the test sample falls\n",
        "    # E.g., if a leaf node contains 20 training samples, with 15 samples of class A and 5 samples of class B,\n",
        "    # the predicted probability for a sample falling into this node would be 0.75 (or 75%) for class A and 0.25 (or 25%) for class B.\n",
        "    probability_predictions. # (100,), a list of 100 (bagging size) 3-class probability predictions, each prediction for 200 points\n",
        "    #print(model.predict_proba(X_test))\n",
        "\n",
        "# Use axis=0 to find the mode along the first dimension - majority voting\n",
        "consensus_predictions = np. # This will make it size (100,200), the values are class predictions 0, 1, 2\n",
        "\n",
        "# Using mode function to return a ModeResult object that contains two arrays: .mode and .count.\n",
        "# The .mode array contains the mode (most common value) of each class\n",
        "consensus_bagged_prediction = mode( # (200,) It will pick one that has the most vote across all baggings. It includes predictions for 200 points\n",
        "\n",
        "# Probability Bagging- predicted probabilities from each model are averaged to make the final prediction\n",
        "probability_predictions = np. # (200,3), averaged across bagging direction (100 baggings), yielding 3-class prob predictions for 200 points\n",
        "probability_bagged_prediction = np.argmax( # (200,), Find among 3 classes, which class has the highest value\n",
        "\n",
        "# Evaluate performance\n",
        "consensus_accuracy = accuracy_score(\n",
        "probability_accuracy = accuracy_score(\n",
        "\n",
        "print(f'Consensus Bagging Accuracy: {}')\n",
        "print(f'Probability Bagging Accuracy: {}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part II: Show the plot how bootstrap size B is related to test error\n"
      ],
      "metadata": {
        "id": "LqAdzZGx-Gxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Question:\n",
        "\n",
        "# Based on the template above, you can add one extra loop for B to store all the consensus_error and probability_error corresponding to each B.\n",
        "# Then make two plots: B vs. consensus_error and B vs. probability_error\n",
        "\n",
        "# Initialize lists to store errors for different B values\n",
        "consensus_errors = []\n",
        "probability_errors = []\n",
        "\n",
        "# Max number of bootstrap samples\n",
        "max_B = 100\n",
        "\n",
        "for B in range(1, max_B + 1):\n",
        "    consensus_predictions = []\n",
        "    probability_predictions = []\n",
        "\n",
        "    # Bagging for B bootstrap samples\n",
        "    for b in range(B):\n",
        "        X_train_b, y_train_b =\n",
        "        model =\n",
        "        model.\n",
        "        consensus_predictions.\n",
        "        probability_predictions.\n",
        "\n",
        "    # Consensus Bagging\n",
        "    consensus_predictions =\n",
        "    consensus_bagged_prediction\n",
        "    ...\n",
        "    consensus_errors\n",
        "\n",
        "    # Probability Bagging\n",
        "    probability_predictions =\n",
        "    probability_bagged_prediction\n",
        "    ...\n",
        "    probability_errors.append\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, max_B + 1), , label='Consensus Bagging Error')\n",
        "plt.plot(range(1, max_B + 1), , label='Probability Bagging Error')\n",
        "plt.xlabel('Number of Bootstrap Samples (B)')\n",
        "plt.ylabel('Test Error')\n",
        "plt.title('Test Error vs. Number of Bootstrap Samples')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_uzZSRpuT7iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part III: Manual implementation of Random Forest"
      ],
      "metadata": {
        "id": "nHODG1vM_5pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Parameters for Random Forest\n",
        "n_estimators = 100  # Number of trees in the forest\n",
        "# max_features is set to the square root of the total number of features (np.sqrt(X_train.shape[1])).\n",
        "# This is a common heuristic used in Random Forests for classification tasks.\n",
        "Nmaxfeatures =   # Number of features to consider at every split for classification\n",
        "\n",
        "# Initialize list to store predictions from all trees\n",
        "forest_predictions = []\n",
        "\n",
        "# Random Forest Algorithm\n",
        "for i in range(n_estimators):\n",
        "    # Create a bootstrap sample of the training data\n",
        "    X_train_b, y_train_b =\n",
        "\n",
        "    # Create a decision tree classifier with random subset of features\n",
        "    # To ensure that each tree in the forest considers a random subset of features at each split,\n",
        "    # we can use the max_features parameter of the DecisionTreeClassifier.\n",
        "    # This parameter controls the number of features to consider when looking for the best split at each node.\n",
        "    # It tells the classifier to consider only this many features at each split. The features are chosen randomly.\n",
        "    tree = DecisionTreeClassifier( # depth control is still expected\n",
        "    tree.\n",
        "\n",
        "    # Store the predictions\n",
        "    forest_predictions. # (100,) a list of 100 (bagging size) for classication of 200 points with values 0, 1, 2\n",
        "\n",
        "# Aggregate predictions using majority vote\n",
        "forest_predictions = np. # This make the size (100,200)\n",
        "forest_majority_vote = mode( # (200,) Pick one (classification for 200 points) across all 100 baggings.\n",
        "\n",
        "# Optional: Ensure the prediction is in the correct shape\n",
        "# Flatten the array to 1D\n",
        "#forest_majority_vote = forest_majority_vote.reshape(-1)\n",
        "\n",
        "# Now use it in accuracy_score\n",
        "forest_accuracy = accuracy_score(\n",
        "\n",
        "print(f\"Random Forest Accuracy: {}\")\n"
      ],
      "metadata": {
        "id": "m5NaWluuYkXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use sklearn.ensemble library to run RandomForestClassifier"
      ],
      "metadata": {
        "id": "DxPA5niOAAzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf_classifier =\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_classifier.\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(\n",
        "print(f\"Random Forest Classifier Accuracy: {}\")\n"
      ],
      "metadata": {
        "id": "-mlk-Iv9bBSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part IV: Manual implementation of Stacking"
      ],
      "metadata": {
        "id": "zdEw-FA4AIA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "'''\n",
        "Train Multiple Base Learners: Train different models on the same dataset.\n",
        "These can be models of different types or the same type with different hyperparameters.\n",
        "Generate Meta-Features: Use the base learners to make predictions on a validation set.\n",
        "These predictions serve as meta-features for the next step.\n",
        "Train the Meta-Learner: Use the meta-features to train another model (the meta-learner).\n",
        "The meta-learner learns how to combine the predictions of the base learners.\n",
        "Final Predictions: Use the base learners to make predictions on the test set,\n",
        "then use the meta-learner to combine these predictions into the final output.\n",
        "'''\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    RandomForestClassifier(n_estimators=10, random_state=42),\n",
        "    GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
        "]\n",
        "\n",
        "# Train base learners and generate meta-features\n",
        "# For each fold, a part of the data is used as\n",
        "# the validation set (the \"held-out\" part), and the remaining data is used as the training set\n",
        "kf = KFold(n_splits=\n",
        "meta_features = np.zeros((len(X_train), len(base_learners)))  # Initialize meta-features\n",
        "\n",
        "for i, learner in enumerate(base_learners): #iterates over each base learner.\n",
        "    # Further iterates over the different folds created by kf.split(X_train),\n",
        "    # which generates indices for splitting the X_train dataset into training and validation sets\n",
        "    for train_index, val_index in :\n",
        "        # In each iteration (for each fold), the base learner is trained on the training part of the fold and\n",
        "        # then makes predictions on the validation part. These predictions are \"out-of-sample\"\n",
        "        # because the validation data was not used for training.\n",
        "        learner.\n",
        "        predictions = learner.) # out-of-sample prediction\n",
        "        # The predictions for the validation set are stored in the corresponding positions of the meta_features matrix.\n",
        "        meta_features[val_index, i] =\n",
        "\n",
        "# Note for meta learner: cv out-of-sample prediction (meta features) => meta learner (logistic regression) ==> response\n",
        "# Train the meta-learner all using training data\n",
        "meta_learner = LogisticRegression(random_state=42)\n",
        "meta_learner.\n",
        "\n",
        "# Retrain base learners on the entire training set\n",
        "for learner in base_learners:\n",
        "    learner.\n",
        "\n",
        "# Generate test meta-features\n",
        "test_meta_features = np.column_stack([ for learner in base_learners])\n",
        "\n",
        "# Final predictions\n",
        "final_predictions = meta_learner.\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(\n",
        "print(f\"Stacking Model Accuracy: {}\")\n"
      ],
      "metadata": {
        "id": "kU0-VALvbzv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use sklearn.ensemble to run StackingClassifier"
      ],
      "metadata": {
        "id": "aLAcN8IaAOut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=10, random_state=42))\n",
        "]\n",
        "\n",
        "# Train and evaluate each base learner\n",
        "for name, learner in base_learners:\n",
        "    learner.\n",
        "    base_predictions = learner.\n",
        "    base_accuracy = accuracy_score(\n",
        "    print(f\"Base Learner {n} Accuracy: {}\")\n",
        "\n",
        "# Define the stacking ensemble\n",
        "stacked_ensemble = (\n",
        "    estimators=, final_estimator=, cv=\n",
        ")\n",
        "\n",
        "# Train the stacked model\n",
        "stacked_ensemble.\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = stacked_ensemble.\n",
        "accuracy = accuracy_score(\n",
        "\n",
        "print(f\"Stacked Model Accuracy: {}\")\n",
        "\n",
        "# Question: Compared to the random forest example before, why is the accuracy worse? How to fix it?\n"
      ],
      "metadata": {
        "id": "mPeyyA4KcXrF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}