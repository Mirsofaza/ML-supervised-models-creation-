{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates the use of sklearn library to\n",
        "1. train a tree using greedy algorithm\n",
        "2. prune the tree by specifying alpha for the regularization\n",
        "3. Find the best alpha with cross validation and visualization"
      ],
      "metadata": {
        "id": "xuOvzUr5UT1k"
      },
      "id": "xuOvzUr5UT1k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part I: Load iris data and simply train a tree with specified alpha for tree pruning"
      ],
      "metadata": {
        "id": "xdMUX7AfUuIk"
      },
      "id": "xdMUX7AfUuIk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ad256d",
      "metadata": {
        "id": "32ad256d"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target # X: (150,4), y: (150,)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(, , , random_state =42)\n",
        "\n",
        "# Create a decision tree classifier with cost-complexity pruning (ccp_alpha)\n",
        "# You can change the value of ccp_alpha to observe different levels of pruning\n",
        "tree_classifier =\n",
        "# Train the classifier on the training data\n",
        "tree_classifier.\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = tree_classifier.\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(\n",
        "print(f\"Accuracy: { * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part II: Use cross validation error as criteria to find the best alpha by grid search"
      ],
      "metadata": {
        "id": "eCmlvp_rU3T7"
      },
      "id": "eCmlvp_rU3T7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f24952c",
      "metadata": {
        "id": "4f24952c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the parameter grid for ccp_alpha\n",
        "param_grid = {'ccp_alpha': np.linspace( ,'min_samples_split': range(}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "# remember tree_classifier = DecisionTreeClassifier(ccp_alpha=0.04, random_state=42) above\n",
        "grid_search = GridSearchCV(\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.\n",
        "\n",
        "# Get all the results, which is a dictionary in Python\n",
        "# results is a dictionary: include key 'param_ccp_alpha' and 'mean_test_score', each having 2400 values\n",
        "results = grid_search.\n",
        "\n",
        "# Find the best score which is the accuracy\n",
        "best_score = grid_search.\n",
        "\n",
        "# Find all ccp_alphas with the best score\n",
        "# First fine the highest mean_test_score that matches the best score found\n",
        "# Then find the corresponding alpha\n",
        "best_ccp_alphas = results[\n",
        "\n",
        "# Select the largest ccp_alpha with the best score\n",
        "best_ccp_alpha =\n",
        "print(f\"Best ccp_alpha: { }\")\n",
        "\n",
        "best_min_samples_split = grid_search.\n",
        "print(f\"Best min_samples_split: {}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_accuracy = grid_search.s\n",
        "print(f\"Test accuracy with best ccp_alpha: {* 100:.2f}%\")\n",
        "\n",
        "# Fit a new tree with the best ccp_alpha to find the tree size\n",
        "best_tree = DecisionTreeClassifier(random_state=0,\n",
        "best_tree\n",
        "\n",
        "# Print the size of the best tree\n",
        "print(f\"Size of the best tree (number of leaves): {best_tree.}\")\n",
        "print(f\"Size of the best tree (number of nodes): {best_tree.}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we visualize how tree size is related to CV_error and Test_error"
      ],
      "metadata": {
        "id": "XRc0qc3IgU-3"
      },
      "id": "XRc0qc3IgU-3"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Get the cost complexity pruning path\n",
        "# Since we do not know the ccp_alpha now, we start with a simple tree model\n",
        "tree_classifier =\n",
        "# computes the \"effective alphas\" and the corresponding impurities for each step of the pruning process.\n",
        "# The number of alphas will be equal to the number of nodes that can be pruned, plus one for the unpruned tree.\n",
        "# The exact number depends on the structure and depth of the tree determined by the data characteristics\n",
        "path = tree_classifier.cost\n",
        "# impurity\" is a measure used to decide how to split the data at each node. Common measures of\n",
        "# impurity include the Gini impurity for classification trees and mean squared error for regression trees\n",
        "ccp_alphas, impurities = path., path. # ccp_alphas or path.impurities has a size of (K,),\n",
        "\n",
        "# Perform cross-validation for each alpha and get the number of leaves\n",
        "cv_errors = []\n",
        "test_errors = []\n",
        "tree_sizes = []\n",
        "# Let's loop for alpha based on the ccp_alphas found from cost complexity pruning above\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf =DecisionTreeClassifier(random_state = 0, )\n",
        "    clf.f  # Fit the model to get the tree size\n",
        "    tree_sizes.  # Get the number of leaves J\n",
        "    # the classifier's performance is evaluated on the test set (X_test, y_test) using the score method\n",
        "    test_errors.append(  # Test error\n",
        "    # Below is for tree size selection based on CV\n",
        "    # the error is 1 - accuracy. This gives us the proportion of incorrect predictions over the cross-validation process\n",
        "    # Then trains the model on 4 folds, and evaluates it on the 1 remaining fold.\n",
        "    # This process is repeated 5 times, each time with a different fold held out for validation.\n",
        "    # The function returns the accuracy scores for each fold\n",
        "    scores = cross_val_score(clf,  # 5-fold cross-validation\n",
        "    # Record error (1- accuracy or score) for each alpha\n",
        "    cv_errors.append(  # CV error to be used to determine alpha or tree size\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(tree_sizes,, marker='o', label='CV Error', color='blue')\n",
        "plt.plot(,, marker='o', label='Test Error', color='orange')\n",
        "plt.xlabel(\"Tree Size (Number of Leaves)\")\n",
        "plt.ylabel(\"Misclassification Error\")\n",
        "plt.title(\"Tree Size vs. Misclassification Error\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pt3bvqUOkgOG"
      },
      "id": "pt3bvqUOkgOG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: Based on the curve above, which tree size should be used?\n",
        "\n"
      ],
      "metadata": {
        "id": "1XkKRlJq0s1d"
      },
      "id": "1XkKRlJq0s1d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}