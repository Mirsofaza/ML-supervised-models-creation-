{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates the implementation of Relevance Vector Machine for binary classification by using Laplace Approximation. You will implement\n",
        "1. Estimation of Kernel\n",
        "2. Laplace approximation to estimate posterior distribution of model parameter\n",
        "3. Iterative update of model parameters c_N and m_N\n",
        "4. Selection of relevance vectors\n",
        "5. Approximation of predictive distribution of the class"
      ],
      "metadata": {
        "id": "wuF3Os8oqT0n"
      },
      "id": "wuF3Os8oqT0n"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#from scipy.special import expit as sigmoid\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "def sigmoid(a):\n",
        "    return 1/(1+np.exp(-a))\n",
        "\n",
        "class RVM:\n",
        "    def __init__(self, s=1.0, l=1.0, threshold_alpha=1e2):\n",
        "        self.l =l\n",
        "        self.s = s\n",
        "        self.threshold_alpha = threshold_alpha # if alpha>threshold_alpha, its corresponding point is not considered relevant\n",
        "\n",
        "    def c_X1X2(self, X1, X2):\n",
        "        sqdists =\n",
        "        K =\n",
        "        return K\n",
        "\n",
        "    def fit(self, X, t):\n",
        "        N = X.shape[0]\n",
        "\n",
        "        # Initialize alpha (hyperparameters), each input point has a corresponding alpha\n",
        "        self.alpha = np.ones(N + 1)  # including bias or intercept\n",
        "\n",
        "        # Kernel matrix + bias column\n",
        "        K =\n",
        "        Phi = # Size 100X101\n",
        "\n",
        "        # Initializations of posterior mean m_N and posterior covariance Sigma_N\n",
        "        self.m_N = np.zeros(N + 1) # Size 101\n",
        "        self.Sigma_N = np.eye(N + 1)\n",
        "        # Start iteration\n",
        "        for _ in range(100):  # A fixed number of iterations for simplicity\n",
        "            y =\n",
        "            D =\n",
        "            Lambda0 =\n",
        "            # Update alpha (Slide 10)\n",
        "            # initializes a new array called alpha_new that has the same shape\n",
        "            # and data type as the array self.alpha, but with all elements set to zero.\n",
        "            alpha_new = np.zeros_like(self.alpha)\n",
        "            # The slide 10 to update alpha has a numerical problem. It is likely that many points have their\n",
        "            # associated alpha's close to zero (irrelevant vectors). Then we encounter divided by zero issue\n",
        "            # We need to add if then condition to handle the extreme case\n",
        "            epsilon = 1e-8  # A small value to prevent division by zero\n",
        "            for i in range(N):\n",
        "                if abs(self.m_N[i]) > : # not divided by 0, then Slide 10\n",
        "                    alpha_new[i] =\n",
        "                else: # If divided by 0, setting a high alpha value for alpha and marking the data to be removed next\n",
        "                    alpha_new[i] = self.threshold_alpha\n",
        "\n",
        "\n",
        "            # Sigma and mean update using Laplace approximation (Slide 8)\n",
        "            # diagonal matrix with alpha as the diagonal element (Slide 6)\n",
        "            self.Sigma_N =\n",
        "            self.m_N =\n",
        "\n",
        "        # Retain only relevant vectors\n",
        "        # if alpha_i (inverse of covariance) is too big, the corresponding coefficient reflecting the ith data influence has zero mean and zero variance\n",
        "        # Then the ith data should not be retained in the dataset\n",
        "        self.relevant_indices =\n",
        "        self.relevant_vectors =\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        N = X.shape[0] # Extract the number of rows in X, X has a size 100X2\n",
        "        pred_pt = np.zeros(N)\n",
        "\n",
        "        for i in range(N): # For each point in X\n",
        "            k =\n",
        "            phi_x = np.concatenate([k.ravel(), [1.0]])  # phi_x is a 101 array\n",
        "            #phi_x size (101,), Sigma_N size (101, 101)\n",
        "            omega_a =\n",
        "            pred_pt[i] =\n",
        "\n",
        "        return pred_pt\n",
        "\n",
        "    def predict(self, X):\n",
        "        # This function predicts class labels for the test data\n",
        "        probas =\n",
        "        return ().astype(int)  # Classify as 1 if probability >= 0.5\n",
        "\n",
        "# Sample data\n",
        "X = np.random.randn(100, 2)\n",
        "t = (X[:, 0] + X[:, 1] > 0).astype(int) # Data 1 for try: Linear decision boundary\n",
        "# t = (X[:, 0]**2 + X[:, 1]**2 < 1).astype(int)  # Data 2 for try:  Circular decision boundary\n",
        "\n",
        "# Training the RVM\n",
        "model = RVM()\n",
        "model.\n",
        "\n",
        "# Predicting\n",
        "y_pred = model.\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the actual data points\n",
        "ax.scatter(X[t==0][:, 0], X[t==0][:, 1], color='blue', label='Class 0', marker='o', s=50)\n",
        "ax.scatter(X[t==1][:, 0], X[t==1][:, 1], color='red', label='Class 1', marker='x', s=50)\n",
        "\n",
        "# Create a grid of points to evaluate classifier's predictions\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Predict class probabilities on this grid\n",
        "Z = model.\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the actual data points with true labels\n",
        "scatter = ax.scatter(, c=t, cmap='viridis', label='True labels', edgecolor='k')\n",
        "\n",
        "# Plot the decision boundary (where Z=0.5)\n",
        "contour = ax.contourf(,,, levels=10, cmap='RdBu', alpha=0.6)\n",
        "plt.colorbar(contour, label='Predicted probability (class 1)')\n",
        "\n",
        "# Plot the predicted labels as 'X' markers on top of the actual data points\n",
        "# This allows us to see where the model's predictions match the true labels\n",
        "for i, txt in enumerate(y_pred):\n",
        "    ax.annotate(, (X[i, 0], X[i, 1]), color='white', weight='bold',\n",
        "                ha='center', va='center')\n",
        "\n",
        "# Set plot titles and labels\n",
        "ax.set_title('RVM Classification Results with Predicted Labels')\n",
        "ax.legend(handles=scatter.legend_elements()[0], labels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "# Question: Change the data to Data 2 circular boundary and rerun the results\n"
      ],
      "metadata": {
        "id": "V7m1140JirgU"
      },
      "id": "V7m1140JirgU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, txt in enumerate(y_pred):\n",
        "  print(i,txt)"
      ],
      "metadata": {
        "id": "BPzUQNLH6rh0"
      },
      "id": "BPzUQNLH6rh0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated implementation of RVM:\n",
        "Sklearn itself does not include any library for running relevance vector machine. We need to install a third-party package sklearn-rvm. Install it first"
      ],
      "metadata": {
        "id": "883qL26sVh1F"
      },
      "id": "883qL26sVh1F"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-rvm"
      ],
      "metadata": {
        "id": "qIhGet81VN5F"
      },
      "id": "qIhGet81VN5F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn_rvm import EMRVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the RVM classifier\n",
        "rvm =   # Using Radial Basis Function (RBF) kernel\n",
        "rvm.\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rvm.\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Plot the decision boundary\n",
        "h = .02  # step size in the mesh\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "# Obtain labels for each point in the mesh using the trained model\n",
        "Z = rvm.\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(,,, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "\n",
        "# Plot the training points\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
        "plt.title('RVM Decision Boundary with Training Points')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CHvPlqLaVORV"
      },
      "id": "CHvPlqLaVORV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the probability of the class..."
      ],
      "metadata": {
        "id": "CU6zeCxGWj-W"
      },
      "id": "CU6zeCxGWj-W"
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue from the previous code...\n",
        "\n",
        "# Obtain probability for class 1 for each point in the mesh\n",
        "# Check if the predict_proba method is available for RVM\n",
        "if hasattr(rvm, \"predict_proba\"):\n",
        "    Z_proba = rvm.  # Probability for class 1\n",
        "    Z_proba = Z_proba.reshape(xx.shape)\n",
        "\n",
        "    # Plot the probability heatmap\n",
        "    plt.contourf cmap=plt.cm.RdBu, alpha=0.8)\n",
        "\n",
        "    # Add a colorbar to show the scale of probabilities\n",
        "    plt.colorbar()\n",
        "\n",
        "# Plot the training points with darker colors for better visibility\n",
        "plt.scatter( c=y_train, cmap=plt.cm.RdBu, edgecolors='k', s=20)\n",
        "\n",
        "# Additional plot settings\n",
        "plt.title('RVM Decision Boundary with Probability Heatmap')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EAspCdozWVq8"
      },
      "id": "EAspCdozWVq8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}